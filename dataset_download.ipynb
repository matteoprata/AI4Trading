{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65cccc1e",
   "metadata": {},
   "source": [
    "# LOB Dataset for Projects\n",
    "\n",
    "This jupyter notebook is used to download the FI-2010 [1] dataset for train and test a AI classifier on LOB data. \n",
    "The code is obtained from [2].\n",
    "\n",
    "### Data:\n",
    "The FI-2010 is publicly avilable and interested readers can check out their paper [1]. The dataset can be downloaded from: https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649 \n",
    "\n",
    "Otherwise, the notebook will download the data automatically or it can be obtained from: \n",
    "\n",
    "https://drive.google.com/drive/folders/1Xen3aRid9ZZhFqJRgEMyETNazk02cNmv?usp=sharing\n",
    "\n",
    "### References:\n",
    "[1] Ntakaris A, Magris M, Kanniainen J, Gabbouj M, Iosifidis A. Benchmark dataset for mid‐price forecasting of limit order book data with machine learning methods. Journal of Forecasting. 2018 Dec;37(8):852-66. https://arxiv.org/abs/1705.03233\n",
    "\n",
    "[2] Zhang Z, Zohren S, Roberts S. DeepLOB: Deep convolutional neural networks for limit order books. IEEE Transactions on Signal Processing. 2019 Mar 25;67(11):3001-12. https://arxiv.org/abs/1808.03668\n",
    "\n",
    "### This notebook runs on Pytorch 1.9.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89391acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-02 13:36:49--  https://raw.githubusercontent.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books/master/data/data.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 56278154 (54M) [application/zip]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>]  53,67M  6,43MB/s    in 8,8s    \n",
      "\n",
      "2021-12-02 13:37:00 (6,08 MB/s) - ‘data.zip’ saved [56278154/56278154]\n",
      "\n",
      "Archive:  data.zip\n",
      "  inflating: Test_Dst_NoAuction_DecPre_CF_7.txt  \n",
      "  inflating: Test_Dst_NoAuction_DecPre_CF_9.txt  \n",
      "  inflating: Test_Dst_NoAuction_DecPre_CF_8.txt  \n",
      "  inflating: Train_Dst_NoAuction_DecPre_CF_7.txt  \n",
      "data downloaded.\n"
     ]
    }
   ],
   "source": [
    "# download the data\n",
    "import os \n",
    "if not os.path.isfile('data.zip'):\n",
    "    !wget https://raw.githubusercontent.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books/master/data/data.zip\n",
    "    !unzip -n data.zip\n",
    "    print('data downloaded.')\n",
    "else:\n",
    "    print('data already existed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb74f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32fe401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x(data):\n",
    "    df1 = data[:40, :].T\n",
    "    return np.array(df1)\n",
    "\n",
    "def get_label(data):\n",
    "    lob = data[-5:, :].T\n",
    "    return lob\n",
    "\n",
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    df = np.array(X)\n",
    "\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX, dataY\n",
    "\n",
    "def torch_data(x, y):\n",
    "    x = torch.from_numpy(x)\n",
    "    x = torch.unsqueeze(x, 1)\n",
    "    y = torch.from_numpy(y)\n",
    "    y = F.one_hot(y, num_classes=3)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be30f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, data, k, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        x = prepare_x(data)\n",
    "        y = get_label(data)\n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        y = y[:,self.k] - 1\n",
    "        self.length = len(x)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90694ed",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We used no auction dataset that is normalised by decimal precision approach in their work. The first seven days are training data and the last three days are testing data. A validation set (20%) from the training set is used to monitor the overfitting behaviours.  \n",
    "\n",
    "The first 40 columns of the FI-2010 dataset are 10 levels ask and bid information for a limit order book and we only use these 40 features in our network. The last 5 columns of the FI-2010 dataset are the labels with different prediction horizons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "299b429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 203800) (149, 50950) (149, 139587)\n"
     ]
    }
   ],
   "source": [
    "# please change the data_path to your local path\n",
    "# data_path = '/nfs/home/zihaoz/limit_order_book/data'\n",
    "\n",
    "dec_data = np.loadtxt('Train_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n",
    "dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n",
    "\n",
    "dec_test1 = np.loadtxt('Test_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_test2 = np.loadtxt('Test_Dst_NoAuction_DecPre_CF_8.txt')\n",
    "dec_test3 = np.loadtxt('Test_Dst_NoAuction_DecPre_CF_9.txt')\n",
    "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "\n",
    "print(dec_train.shape, dec_val.shape, dec_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18387ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([203701, 1, 100, 40]) torch.Size([203701])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataset_train = Dataset(data=dec_train, k=4, num_classes=3, T=100)\n",
    "dataset_val = Dataset(data=dec_val, k=4, num_classes=3, T=100)\n",
    "dataset_test = Dataset(data=dec_test, k=4, num_classes=3, T=100)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(dataset_train.x.shape, dataset_train.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0b27757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item:\n",
      "tensor([[[[0.3650, 0.0041, 0.3645,  ..., 0.0020, 0.3630, 0.0061],\n",
      "          [0.3650, 0.0041, 0.3645,  ..., 0.0020, 0.3630, 0.0061],\n",
      "          [0.3650, 0.0041, 0.3645,  ..., 0.0020, 0.3630, 0.0061],\n",
      "          ...,\n",
      "          [0.3653, 0.0053, 0.3645,  ..., 0.0020, 0.3615, 0.0005],\n",
      "          [0.3653, 0.0053, 0.3645,  ..., 0.0020, 0.3615, 0.0005],\n",
      "          [0.3653, 0.0053, 0.3645,  ..., 0.0020, 0.3615, 0.0005]]]],\n",
      "       dtype=torch.float64)\n",
      "Single time snapshot inside the item:\n",
      "tensor([[[0.3650, 0.0041, 0.3645, 0.0049, 0.3652, 0.0068, 0.3644, 0.0017,\n",
      "          0.3653, 0.0198, 0.3640, 0.0051, 0.3654, 0.0216, 0.3639, 0.0060,\n",
      "          0.3655, 0.0025, 0.3637, 0.0036, 0.3657, 0.0150, 0.3636, 0.0022,\n",
      "          0.3658, 0.0010, 0.3634, 0.0020, 0.3659, 0.0053, 0.3633, 0.0175,\n",
      "          0.3660, 0.0065, 0.3631, 0.0050, 0.3662, 0.0020, 0.3630, 0.0061]]],\n",
      "       dtype=torch.float64)\n",
      "Label:\n",
      "tensor([2.], dtype=torch.float64)\n",
      "torch.Size([1, 1, 100, 40]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(\"Item:\")\n",
    "    print(x)\n",
    "    print(\"Single time snapshot inside the item:\")\n",
    "    print(x[:, :, 0]) # best-sell price, best-sell- volume, best-buy price, best-buy volume,\n",
    "    # 2-sell price, 2sell- volume,  2buy price, 2buy volume\n",
    "    print(\"Label:\")\n",
    "    print(y)  # label to predice\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1b23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15734d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
