{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Artificial Intelligence for Trading (Lab Lecture 1)\n",
    "**Contacts: novella@di.uniroma1.it, coletta@di.uniroma1.it, piva@di.uniroma1.it, prata@di.uniroma1.it**\n",
    "\n",
    "## Introduction to Pandas\n",
    "In this first part of the course, you will learn to **manipulate financial data with Python**. \n",
    "\n",
    "We will start by handling **pandas** (<a href=\"https://pandas.pydata.org/docs/\">doc</a>), which is a Python package providing fast, flexible, and expressive data structures designed to make working\n",
    "with “relational” or “labeled” data both easy and intuitive. It aims to be a high-level building\n",
    "block for doing practical, real world **data analysis** in Python.\n",
    "\n",
    "The two primary data structures of pandas, **Series** (1-dimensional) and **DataFrame** (2-dimensional), handle\n",
    "the vast majority of typical use cases in finance, statistics, social science, and many areas of engineering.\n",
    "pandas is built on top of NumPy and is intended to integrate well within a scientific computing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.display.width = 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **DataFrame** is a 2-dimensional data structure that can store data of different types (including characters,\n",
    "integers, floating point values, categorical data and more) in columns. It is similar to a spreadsheet, a\n",
    "SQL table or the data.frame in R. Let us create one and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# creating a dataframe by columns\n",
    "data_cols = {\"Name\":[\"Alice\", \"Bob\", \"Claire\", \"Daniel\"], \"Age\":[12, 23, 44, 59]}  # as a dictionary, column wise\n",
    "df = pd.DataFrame(data_cols)\n",
    "print(df)\n",
    "\n",
    "# equivalently by rows\n",
    "data_rows = [(\"Alice\", 12), (\"Bob\", 23), (\"Claire\", 44), (\"Daniel\", 59)]  # as a list, row wise\n",
    "df = pd.DataFrame(data_rows, columns=['Name','Age'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be dealing with data coming from **CSV** (**C**omma **S**eparated **V**alues) files. Here is an example of a CSV dataset of videos trending on Youtube.\n",
    "\n",
    "<img src=\"data/press_images/YT_table.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Manipulating Real Stock Market Dataset\n",
    "You can download real stock market dataset at https://finance.yahoo.com. They will look like the picture below (**AAPL.csv**). \n",
    "\n",
    "<img src=\"data/press_images/AAPL_table.png\" width=\"600\" height=\"700\"/>\n",
    "\n",
    "Notice: a trading day starts at 9:30 a.m. and ends at 4:00 p.m.. There is no trading activity during weekends and holidays. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_01():\n",
    "    \"\"\" Print the whole dataframe. \"\"\"\n",
    "    df = pd.read_csv(\"data/AAPL.csv\")\n",
    "    print(df)\n",
    "\n",
    "test_01()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_02():\n",
    "    \"\"\" Print the first 5 lines of a dataframe. \"\"\"\n",
    "    df = pd.read_csv(\"data/AAPL.csv\")\n",
    "    print(df.head())\n",
    "\n",
    "test_02()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_03():\n",
    "    \"\"\" Print a slice of a dataframe. \"\"\"\n",
    "    df = pd.read_csv(\"data/AAPL.csv\")\n",
    "    \n",
    "    # Access a group of rows and columns by integer index\n",
    "    print(df.iloc[10:21])  # rows between index 10 and 20 (by slicing)\n",
    "\n",
    "test_03()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_max_adjclose(symbol):\n",
    "    \"\"\" Returns the max value of CLOSE of the symbol. \"\"\"\n",
    "    df = pd.read_csv(\"data/%s.csv\" % symbol)\n",
    "    return df['Adj Close'].max()\n",
    "\n",
    "def test_04():\n",
    "    \"\"\" Print some symbol names along with the max adj closing price for that symbol. \"\"\"\n",
    "    for symbol in ['AAPL', 'TSLA', 'MSFT']:\n",
    "        print(\"Max adj close\", symbol, get_max_adjclose(symbol))\n",
    "\n",
    "test_04()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_05():\n",
    "    \"\"\" Plot the adjusted close for Apple. \"\"\"\n",
    "    df = pd.read_csv(\"data/AAPL.csv\")\n",
    "    df['Adj Close'].plot()\n",
    "    plt.show()\n",
    "    \n",
    "test_05()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_06():\n",
    "    \"\"\" Plot high and low for Tesla. \"\"\"\n",
    "    df = pd.read_csv(\"data/TSLA.csv\")\n",
    "    df[['High', 'Low']].plot(title=\"TSLA Stock\")\n",
    "    plt.show()\n",
    "\n",
    "test_06()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_07():\n",
    "    \"\"\" Assign an index to a new dataframe. \"\"\"\n",
    "    # dates is formatted as YYYY-MM-DD\n",
    "    \n",
    "    start_date = '2019-10-09'\n",
    "    end_date = '2020-02-01'\n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "    print(dates) # DatetimeIndex object with timestamps\n",
    "     \n",
    "    df = pd.DataFrame(index=dates) # the dataframe only with the index\n",
    "    print(df)\n",
    "\n",
    "test_07()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_08():\n",
    "    \"\"\" Join an empty DataFrame with index, with the Apple Dataframe. \"\"\"\n",
    "\n",
    "    # dates is formatted as YYYY-MM-DD\n",
    "    start_date = '2019-10-09'\n",
    "    end_date = '2020-02-01'\n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "\n",
    "    # An empy dataframe\n",
    "    df1 = pd.DataFrame(index=dates) # the dataframe only with the index\n",
    "    \n",
    "    # join with Apple stock, attempt 1\n",
    "    dfAAPL = pd.read_csv(\"data/AAPL.csv\")\n",
    "    df1 = df1.join(dfAAPL)  # join by the index by defult\n",
    "    \n",
    "    # join with Apple stock, attempt 2\n",
    "    # dfAAPL = pd.read_csv(\"data/AAPL.csv\", index_col=\"Date\", parse_dates=True) \n",
    "    # df1 = df1.join(dfAAPL)\n",
    "\n",
    "    # join with Apple stock, attempt 3\n",
    "    # dfAAPL = pd.read_csv(\"data/AAPL.csv\", index_col=\"Date\", parse_dates=True) \n",
    "    # # {‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘left’\n",
    "    # df1 = df1.join(dfAAPL, how=\"inner\") \n",
    "\n",
    "    # join with Apple stock, attempt 4\n",
    "    # dfAAPL = pd.read_csv(\"data/AAPL.csv\", index_col=\"Date\", parse_dates=True, usecols=[\"Date\", \"Adj Close\"])\n",
    "    # df1 = df1.join(dfAAPL, how=\"inner\")\n",
    "    \n",
    "    print(df1)\n",
    "\n",
    "test_08()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def path_to_symbol(symbol_name, root_symbols=\"data\"):\n",
    "    \"\"\"Returns the path to the symbol. \"\"\"\n",
    "    return os.path.join(root_symbols, \"%s.csv\" % symbol_name)\n",
    "\n",
    "def adjusted_close_symbols(symbols, dates=('2019-10-09', '2020-10-09')):\n",
    "    \"\"\" Joins an empty DataFrame with index, with multiple stocks dataframes. \"\"\"\n",
    "\n",
    "    # dates is formatted as YYYY-MM-DD\n",
    "    start_date, end_date = dates\n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "\n",
    "    # An empty dataframe\n",
    "    df1 = pd.DataFrame(index=dates) # the dataframe only with the index\n",
    "\n",
    "    for sym in symbols:\n",
    "        dfSYM = pd.read_csv(path_to_symbol(sym), index_col=\"Date\", parse_dates=True,\n",
    "                            usecols=[\"Date\", \"Adj Close\"], na_values=['nan'])\n",
    "        dfSYM = dfSYM.rename(columns= {'Adj Close': sym})\n",
    "        df1 = df1.join(dfSYM, how=\"inner\")\n",
    "\n",
    "    return df1\n",
    "\n",
    "def test_09():\n",
    "    df = adjusted_close_symbols([\"^GSPC\", \"AAPL\", \"TSLA\", \"FB\", \"MSFT\"])\n",
    "    print(df)\n",
    "\n",
    "test_09()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_10():\n",
    "    \"\"\" Slicing. \"\"\"\n",
    "    df = adjusted_close_symbols([\"^GSPC\", \"AAPL\", \"TSLA\", \"FB\", \"MSFT\"])\n",
    "\n",
    "    # Slicing over the rows, loc: access a group of rows and columns by label(s) or a boolean array.\n",
    "    df1 = df.loc['2020-03-01':'2020-03-31']  # iloc for integer indices, loc for labels\n",
    "    print(df1)\n",
    "\n",
    "    # Slicing over the columns\n",
    "    df2 = df[['^GSPC', 'AAPL']]  # Notice no .loc here\n",
    "    print(df2)\n",
    "\n",
    "    # Slicing over both dimensions\n",
    "    df2 = df.loc['2020-03-01':'2020-03-31', ['^GSPC', 'AAPL']]\n",
    "    print(df2)\n",
    "\n",
    "test_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_dataframe(df, title, xlabel, ylabel):\n",
    "    \"\"\"It will plot the dataframe, given a plot tile and labels for the axes. \"\"\"\n",
    "    ax = df.plot(title=title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "def test_11():\n",
    "    \"\"\" Normalising and plotting multiple stock prices. \"\"\"\n",
    "    df = adjusted_close_symbols([\"^GSPC\", \"AAPL\", \"FB\", \"MSFT\"])\n",
    "    plot_dataframe(df, \"Adjusted Closes\", \"Date\", \"Price\")\n",
    "    print(df)\n",
    "\n",
    "    # What to do if you want all the stocks to start at 1.0?\n",
    "    # We want to divide by day 1\n",
    "    df_norm = df / df.iloc[0,:]\n",
    "    plot_dataframe(df_norm, \"Adjusted Closes\", \"Date\", \"Price\")\n",
    "\n",
    "test_11()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Statistics Over Time Series\n",
    "Pandas makes it easy to compute convenient global statistics on a dataframe: **mean, median, std, sum** and\n",
    "<a href=\"https://pandas.pydata.org/pandas-docs/stable/api.html#api-dataframe-stats\">more</a>; and rolling\n",
    "statistics: **rolling mean, rolling std** and <a href=\"http://pandas.pydata.org/pandas-docs/stable/computation.html?highlight=rolling%20statistics#moving-rolling-statistics-moments\">more</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_12():\n",
    "    \"\"\" Print global statistics [mean]. \"\"\"\n",
    "    df = adjusted_close_symbols([\"^GSPC\", \"AAPL\", \"FB\", \"MSFT\"])\n",
    "    print(df.mean())\n",
    "\n",
    "test_12()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An example of rolling mean.\n",
    "\n",
    "<img src=\"data/press_images/rolling_mean.gif\" hight=\"500\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_13():\n",
    "    \"\"\" Print rolling statistics [mean]. We take snapshots of the statistic over time windows, and save it,\n",
    "    move the window of one unit and star again. \"\"\"\n",
    "\n",
    "    df = adjusted_close_symbols([\"AAPL\"])\n",
    "\n",
    "    window_size = 20  # days\n",
    "    aapl_rm = df.rolling(window_size).mean()\n",
    "    \n",
    "    ax = aapl_rm.plot()\n",
    "    df.plot(ax=ax)\n",
    "    ax.axhline(y=df.mean()[0], color='r', linestyle='-', label=\"global mean\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "test_13()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction to NumPy\n",
    "**NumPy** (<a href=\"https://numpy.org/doc/1.19/\">doc</a>) is an open source project aiming to enable numerical computing with Python. NumPy is developed in\n",
    "the open on GitHub, through the consensus of the NumPy and wider scientific Python community.\n",
    "\n",
    "NumPy’s main object is the **homogeneous multidimensional array**. It is a table of elements (usually numbers),\n",
    "all of the same type, indexed by a tuple of non-negative integers. In NumPy dimensions are called axes.\n",
    "NumPy’s array class is called ndarray. It is also known by the alias array.\n",
    "\n",
    "It is related to pandas as a DataFrame is a wrapper of an ndarray. Treating data as ndarrays rather than\n",
    "just DataFrames will give you access to many additional routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_csv(\"data/MSFT.csv\").head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# creating ndarrays\n",
    "d1_ndarray = np.array([1,2,3])  # 1D\n",
    "d2_ndarray = np.array([[1,2,3], [4,5,6], [7,8,9]])  # 2D\n",
    "\n",
    "print(d1_ndarray)\n",
    "print(d2_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# init ndarrays\n",
    "d2_zero = np.zeros((3,3))  # also ones!\n",
    "\n",
    "print(d2_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d2_rand_int = np.random.randint(0,100,(4,4))\n",
    "d1_rand = np.random.rand(4,4)\n",
    "\n",
    "print(d2_rand_int)\n",
    "print(d1_rand)\n",
    "print(d1_rand.shape, d1_rand.size, d1_rand.dtype)\n",
    "\n",
    "# you can also sample from different distribution other than uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_14():\n",
    "    \"\"\" Extract an ndarray from a DataFrame object and play with slicing. \"\"\"\n",
    "\n",
    "    df = adjusted_close_symbols([\"^GSPC\", \"AAPL\", \"FB\", \"MSFT\"], ('2020-10-01', '2020-10-09'))\n",
    "     \n",
    "    nd1 = df.values\n",
    "    print(nd1, type(nd1))\n",
    "\n",
    "    # access a value\n",
    "    print(\"Element in 0,0:\", nd1[0,0])  # [row, column]\n",
    "    print(\"Element in 2,1:\", nd1[2,1])  # [row, column]\n",
    "    \n",
    "    # access slices\n",
    "    print(nd1[0:3,1:3])  # [row, column]\n",
    "\n",
    "    # access rows and columns\n",
    "    print(\"Row 0:\", nd1[0,:])\n",
    "    print(\"Column 0:\", nd1[:,0])\n",
    "\n",
    "    # negative indices\n",
    "    print(nd1[-1, 1:3])\n",
    "\n",
    "    # Replace slices\n",
    "    nd1[0:3,0:2] = nd1[3:,2:]\n",
    "    print(nd1)\n",
    "\n",
    "test_14()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_15():\n",
    "    \"\"\" Operations over axes. \"\"\"\n",
    "\n",
    "    np.random.seed(199)  # seed the random generator\n",
    "    d2_rand_int = np.random.randint(0,100,(3,7))\n",
    "    print(d2_rand_int) \n",
    "\n",
    "    print(\"Sum of each column:\\n\", d2_rand_int.sum(axis=0))  # sum the vales on the rows, encoded as 0\n",
    "    print(\"Sum of each row:\\n\", d2_rand_int.sum(axis=1))  # sum the vales on the rows, encoded as 0\n",
    "\n",
    "    print(\"Minimum of each row:\\n\", d2_rand_int.min(axis=0))\n",
    "    print(\"Maximum of each row:\\n\", d2_rand_int.min(axis=1))\n",
    "    print(\"Mean of all:\\n\", d2_rand_int.mean())  # axis 1 = what to iterate first\n",
    "\n",
    "test_15()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def manual_sum(arr):\n",
    "    sum = 0\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            sum += arr[i,j]\n",
    "    return sum\n",
    "\n",
    "def test_16():\n",
    "    \"\"\" Timing numpy. \"\"\"\n",
    "\n",
    "    np.random.seed(199)  # seed the random generator\n",
    "    d1_rand = np.random.rand(2000, 2000)\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(np.sum(d1_rand))\n",
    "    t2 = time.time()\n",
    "    elapsed_np = t2 - t1\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(manual_sum(d1_rand))\n",
    "    t2 = time.time()\n",
    "    elapsed_man = t2 - t1\n",
    "\n",
    "    print(\"Seconds elapsed for numpy\", elapsed_np)\n",
    "    print(\"Seconds elapsed for manual\", elapsed_man)\n",
    "\n",
    "test_16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_17():\n",
    "    \"\"\" Indexing. \"\"\"\n",
    "\n",
    "    d1_rand = np.random.rand(20)\n",
    "    indices = np.array([0,10,15,19])\n",
    "    print(d1_rand)\n",
    "    print(d1_rand[indices])\n",
    "\n",
    "    # select all the elements lower than the mean of array\n",
    "    mean = d1_rand.mean()\n",
    "    print(mean)\n",
    "    print(d1_rand<mean)  # mask\n",
    "\n",
    "    d1_rand = d1_rand[d1_rand<mean]\n",
    "    print(d1_rand)\n",
    "\n",
    "test_17()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_18():\n",
    "    \"\"\" Operations. \"\"\"\n",
    "\n",
    "    a = np.array([[1,2,3,4,5], [10,20,30,40,50]])\n",
    "    b = np.array([[100,200,300,400,500], [1,2,3,4,5]])\n",
    "    print(\"A matrix\\n\", a)\n",
    "    print(\"B matrix\\n\", b)\n",
    "    \n",
    "    # element wise multiplication \n",
    "    print(\"Multiplication by 2\\n\", 2*a)\n",
    "\n",
    "    # element wise division \n",
    "    print(\"Division by 2\\n\", a / 2)\n",
    "    \n",
    "    # element wise sum\n",
    "    print(\"Sum a and b\\n\", a+b)\n",
    "\n",
    "    # element wise multiplication\n",
    "    print(\"Multiplication a and b\\n\", a*b)\n",
    "\n",
    "    # matrix multiplication\n",
    "    print(\"Mat mul a and b\\n\", np.matmul(a, np.transpose(b)))\n",
    "    \n",
    "    # When the dataframe contains only numbers (exclusing hedar and index) and have the same index\n",
    "    # you can use dataframes as if they were ndarrays \n",
    "            \n",
    "test_18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook and more is available for download at: https://github.com/matteoprata/AI4Trading_20_21"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}